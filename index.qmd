---
title: "Forecasting Lending Amount in Australia Economy Through Bayesian VAR Approach"
author: "Zheyuan Li"

execute:
  echo: false
  
bibliography: references.bib
---

> Abstract: This paper aims to forecast the Australian lending amounts using a Bayesian Var approach. Briefly introduce the research method and and purpose.

> **Keywords.** bsvars, forecasting, credit market, lending amount, shrinkage, housing market


```{r,message=FALSE, warning=FALSE}
library(readabs)
library(readrba)
library(zoo)
library(tseries)
library(tidyr)
library(dplyr)
library(forecast)
library(ggplot2)
library(lubridate)
library(httr)
library(readxl)
library(gridExtra)
library(knitr)
library(kableExtra)
response_1 <- GET("https://www.rba.gov.au/statistics/tables/xls/f01hist.xlsx?v=2024-04-03-12-05-38")
temp_file_1 <- tempfile(fileext = ".xlsx")
writeBin(content(response_1, "raw"), temp_file_1)
data <- read_excel(temp_file_1,sheet = 1, skip = 1 )
data <- data[-(1:12), ]
origin_date <- as.Date("1899-12-30")
data[[1]] <- origin_date + as.numeric(data[[1]]) - 2
dates = data[1]
Cash_Rate_Target <- data$`Cash Rate Target`;
Cash_Rate_Target = as.numeric(Cash_Rate_Target)
plot_data <- data.frame(Date = dates, Cash_Rate_Target = Cash_Rate_Target)
Cash_Rate_Target = na.omit(Cash_Rate_Target)
plot_data <- na.omit(plot_data[c("Title", "Cash_Rate_Target")])
plot_data <- plot_data %>% 
  filter(Title >= as.Date("1991-01-01") & Title <= as.Date("2022-12-31"))
```

```{r,message=FALSE, warning=FALSE}
response_2 <- GET("https://www.abs.gov.au/statistics/labour/employment-and-unemployment/labour-force-australia-detailed/feb-2024/6291014a.xlsx")
temp_file_2 <- tempfile(fileext = ".xlsx")
writeBin(content(response_2, "raw"), temp_file_2)
data_2 <- read_excel(temp_file_2, sheet = 2)
data_2 <- data_2[-(1:9), ]
origin_date <- as.Date("1899-12-30")
data_2[[1]] <- origin_date + as.numeric(data_2[[1]]) - 2
dates = data_2[1]
Unemployment <- data_2$`Unemployed total ;  Persons ;`
Unemployment = as.numeric(Unemployment)
Unemployment <- log(Unemployment)
plot_data_2 <- data.frame(Date = dates, Unemployment = Unemployment)
plot_data_2 <- plot_data_2 %>% 
  filter(...1 >= as.Date("1991-01-01") & ...1  <= as.Date("2022-12-31"))
```

```{r,message=FALSE, warning=FALSE}
response_3 <- GET("https://www.rba.gov.au/statistics/tables/xls/d03hist.xlsx?v=2024-04-02-00-51-45")
temp_file_3 <- tempfile(fileext = ".xlsx")
writeBin(content(response_3, "raw"), temp_file_3)
data_3 <- read_excel(temp_file_3, sheet = 1,skip = 1)
data_3 <- data_3[-(1:9), ]
origin_date <- as.Date("1899-12-30")
data_3[[1]] <- origin_date + as.numeric(data_3[[1]]) - 2
dates = data_3[1]
M1 <- data_3$M1
M1 = as.numeric(M1)
M1 <- log(M1)
plot_data_3 <- data.frame(Date = dates, M1_Amount = M1)
plot_data_3 <- na.omit(plot_data_3[c("Title", "M1_Amount")])
M1 = na.omit(M1)
plot_data_3 <- plot_data_3 %>% 
  filter(Title >= as.Date("1991-01-01") & Title <= as.Date("2022-12-31"))
```

```{r,message=FALSE, warning=FALSE}
response_4 <- GET("https://www.abs.gov.au/statistics/economy/price-indexes-and-inflation/producer-price-indexes-australia/dec-2023/642701.xlsx")
temp_file_4 <- tempfile(fileext = ".xlsx")
writeBin(content(response_4, "raw"), temp_file_4)
data_4 <- read_excel(temp_file_4, sheet = 2)
data_4 <- data_4[-(1:9), ]
origin_date <- as.Date("1899-12-30")
data_4[[1]] <- origin_date + as.numeric(data_4[[1]]) - 2
dates = data_4[1]
PPI <- data_4$`Index Numbers ;  Final ;  Total (Source) ;`
PPI = as.numeric(PPI)
PPI <- log(PPI)
plot_data_4 <- data.frame(Date = dates, PPI = PPI)
```

```{r,message=FALSE, warning=FALSE}
response_5 = GET("https://www.abs.gov.au/statistics/economy/price-indexes-and-inflation/consumer-price-index-australia/dec-quarter-2023/640101.xlsx")
temp_file_5 <- tempfile(fileext = ".xlsx")
writeBin(content(response_5, "raw"), temp_file_5)
data_5 <- read_excel(temp_file_5, sheet = 2)
data_5 <- data_5[-(1:9), ]
origin_date <- as.Date("1899-12-30")
data_5[[1]] <- origin_date + as.numeric(data_5[[1]]) - 2
dates = data_5[1]
CPI <- data_5$`Index Numbers ;  All groups CPI ;  Australia ;`
CPI = as.numeric(CPI)
CPI <- log(CPI)
plot_data_5 <- data.frame(Date = dates, CPI_Amount = CPI)
plot_data_5 <- plot_data_5 %>% 
  filter(...1 >= as.Date("1991-01-01") & ...1 <= as.Date("2023-3-31"))
plot_data_5$`...1` <- as.Date(plot_data_5$`...1`, "%m %Y-%d")
plot_data_5$...1 <- as.Date(cut(plot_data_5$...1, breaks = "quarter"), format = "%Y-%m-%d") - 1

full_seq <- seq(from = as.Date(sprintf("%s-01-01", min(format(plot_data_5$...1, "%Y")))), 
                to = as.Date(sprintf("%s-12-01", max(format(plot_data_5$...1, "%Y")))), 
                by = "month")

zoo_data <- zoo(plot_data_5$CPI_Amount, plot_data_5$...1)

zoo_full <- zoo(order.by = full_seq)
zoo_merged <- merge(zoo_data, zoo_full, all = TRUE)

zoo_interpolated <- na.approx(zoo_merged)
plot_data_monthly <- data.frame(Date = index(zoo_interpolated), CPI_Amount = coredata(zoo_interpolated))
plot_data_5 <- plot_data_monthly[!duplicated(format(plot_data_monthly$Date, "%Y-%m")), ]
plot_data_5 <- plot_data_5 %>% 
  filter(Date >= as.Date("1991-01-01") & Date <= as.Date("2022-12-31"))
```

```{r,message=FALSE, warning=FALSE}
response_6 = GET("https://www.abs.gov.au/statistics/economy/national-accounts/australian-national-accounts-national-income-expenditure-and-product/dec-2023/5206002_Expenditure_Volume_Measures.xlsx")
temp_file_6 <- tempfile(fileext = ".xlsx")
writeBin(content(response_6, "raw"), temp_file_6)
data_6 <- read_excel(temp_file_6, sheet = 2)
data_6 <- data_6[-(1:9), ]
origin_date <- as.Date("1899-12-30")
data_6[[1]] <- origin_date + as.numeric(data_6[[1]]) - 2
dates = data_6[1]
GDP <- data_6$`GROSS DOMESTIC PRODUCT ;...124`
GDP = as.numeric(GDP)
GDP <- log(GDP)
plot_data_6 <- data.frame(Date = dates, GDP_Amount = GDP)
plot_data_6 <- plot_data_6 %>% 
  filter(...1 >= as.Date("1991-01-01") & ...1 <= as.Date("2023-3-31"))
plot_data_6$`...1` <- as.Date(plot_data_6$`...1`, "%m %Y-%d")
plot_data_6$...1 <- as.Date(cut(plot_data_6$...1, breaks = "quarter"), format = "%Y-%m-%d") - 1

full_seq <- seq(from = as.Date(sprintf("%s-01-01", min(format(plot_data_6$...1, "%Y")))), 
                to = as.Date(sprintf("%s-12-01", max(format(plot_data_6$...1, "%Y")))), 
                by = "month")

zoo_data <- zoo(plot_data_6$GDP_Amount, plot_data_6$...1)

zoo_full <- zoo(order.by = full_seq)
zoo_merged <- merge(zoo_data, zoo_full, all = TRUE)

zoo_interpolated <- na.approx(zoo_merged)
plot_data_monthly <- data.frame(Date = index(zoo_interpolated), GDP_Amount = coredata(zoo_interpolated))
plot_data_6 <- plot_data_monthly[!duplicated(format(plot_data_monthly$Date, "%Y-%m")), ]
plot_data_6 <- plot_data_6 %>% 
  filter(Date >= as.Date("1991-01-01") & Date <= as.Date("2022-12-31"))
```

```{r,message=FALSE, warning=FALSE}
response_7 = GET("https://www.rba.gov.au/statistics/tables/xls/d05hist.xlsx?v=2024-04-02-14-20-19")
temp_file_7 <- tempfile(fileext = ".xlsx")
writeBin(content(response_7, "raw"), temp_file_7)
data_7 <- read_excel(temp_file_7, sheet = 1, skip = 1)
data_7 <- data_7[-(1:9), ]
origin_date <- as.Date("1899-12-30")
data_7[[1]] <- origin_date + as.numeric(data_7[[1]]) - 2
dates = data_7[1]
Houselend <- data_7$`Lending to persons; Housing; Owner-occupiers`
Houselend = as.numeric(Houselend)
Houselend <- log(Houselend)
plot_data_7 <- data.frame(Date = dates, Houselend_Amount = Houselend)
plot_data_7 <- plot_data_7 %>% 
  filter(Title >= as.Date("1991-01-01") & Title <= as.Date("2022-12-31"))
```

```{r,message=FALSE, warning=FALSE}
response_8 = GET("https://www.rba.gov.au/statistics/tables/xls/d05hist.xlsx?v=2024-04-02-14-20-19")
temp_file_8 <- tempfile(fileext = ".xlsx")
writeBin(content(response_8, "raw"), temp_file_8)
data_8 <- read_excel(temp_file_8, sheet = 1, skip = 1)
data_8 <- data_8[-(1:9), ]
origin_date <- as.Date("1899-12-30")
data_8[[1]] <- origin_date + as.numeric(data_8[[1]]) - 2
dates = data_8[1]
Businesslend <- data_8$`Commercial lending; Business sector`
Businesslend = as.numeric(Businesslend)
Businesslend <- log(Businesslend)
plot_data_8 <- data.frame(Date = dates, Businesslend_Amount = Businesslend)
Businesslend = na.omit(Businesslend)
plot_data_8 <- plot_data_8 %>% 
  filter(Title >= as.Date("1991-01-01") & Title <= as.Date("2022-12-31"))
```

```{r,message=FALSE, warning=FALSE}
m1_n = read_rba(series_id = "DMAM1S") 
m1_n <- m1_n %>% filter(date > as.Date("1899-12-31"))

m1_n <- m1_n %>%
  mutate(Quarter = paste(year(date), quarter(date), sep = "Q")) %>%
  group_by(Quarter) %>%
  summarize(Average = mean(value, na.rm = TRUE))

```

## Introduction

This project is focusing on the credit market in Australia. It intends to use Bayesian VAR approach in forecasting of lending amounts in housing and business sector.

**The Research Objective and Question:** The research focuses on predicting lending trends in Australia, with an emphasis on the amounts of lending. Therefore, the question I want to answer is: How can we accurately predict Australia's lending indicators, and what do these forecasts reveal through BVAR?

**Motivation of Research:** For banks and financial institutions, managing the interest rate associated with future fluctuations is crucial. Precise forecasts of lending amounts can aid these institutions in more effectively assessing and managing lending rates, which in turn helps in protecting their assets and ensuring financial stability.

## Data and Properties

This section shows the data collection process and their descriptive statistic including their series plotting and basic properties through unit-root test.

### Variables Selection

The selection of variables grounds in several macroeconomic indicators, derived from the official databases of the Australian Bureau of Statistics (ABS) and the Reserve Bank of Australia (RBA). The rationale for the choice of variables is informed by the work of scholars Marta Bańbura, Domenico Giannone, and Michele Lenza (2015) on European macroeconomic forecasting. This research takes similar variables in macroeconomic forecasting,including the credit market.

These indicators are closely linked to lending market. An increase in PPI and CPI indices signifies a decline in the purchasing power of money, necessitating a rise in loan rates to compensate for inflationary losses. Growth in GDP indicates economic expansion, leading to increased demand for capital, and consequently, higher lending volumes. Higher unemployment rates suggest an economic downturn, prompting banks to lower interest rates to stimulate the economy. Additionally, an abundance of monetary supply leads banks to reduce loan rates to attract more borrowers. Also, the cash target rate will influences the loan amount by affecting borrowing costs; when lowered, borrowing becomes cheaper, stimulating loan demand, The cash target rate impacts loan market volume by altering borrowing costs: lower rates stimulate loan demand, while higher rates may reduce it.

Therefore, in my project, these following specific variables are used in BVAR model:

-   $m1_t$: M1 aggregate from RBA Database

-   $cpi_t$: CPI aggregate from ABS Database

-   $cashrate_t$: Cash Rate Target aggregate from RBA Database

-   $gdp_t$: Expenditure on Gross Domestic Product (GDP) aggregate from ABS Database

-   $unemploy_t$: Unemplyemnt person aggregate from ABS Database

-   $ppi_t$: PPI aggregate from ABS Database

For the loan volumes to be forecasted, I have categorized them into housing loans and commercial loans, as they represent two distinct types of demand. The underlying logic influenced by macroeconomic factors might differ between them:

-   $houselend_t$: House lending volume aggregate from RBA

-   $businesslend_t$: Business lending volume aggregate from RBA

### Transformation and Properties of the Variables

The cash rate target, $cashrate_t$, is in percentages so it doesn't nedd to be transformed. All other variables are applied in the log-transformation and the result are below:

-   $m1_t=\log(m1_t)$

-   $cpi_t=\log(cpi_t)$

-   $gdp_t=\log(gdp_t)$

-   $unemploy_t=\log(unemploy_t)$

-   $ppi_t=\log(ppi_t)$

-   $houselend_t=\log(houselend_t)$

-   $businesslend_t=\log(businesslend_t)$

Their time series plots result are below:

```{r warning=FALSE}
#| echo: false
#| message: false
#| warning: false
#| label: fig-line-plot
#| fig-cap: "Time Series Plots for Variables"

p1 = ggplot(plot_data, aes(x = Title, y = Cash_Rate_Target)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'Cash_Rate')

p2 = ggplot(plot_data_2, aes(x = ...1, y = Unemployment)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'Unemploy')

p3 = ggplot(plot_data_3, aes(x = Title, y = M1_Amount)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'M1')

p4 = ggplot(plot_data_4, aes(x = ...1, y = PPI)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'PPI')

p5 = ggplot(plot_data_5, aes(x = Date, y = CPI_Amount)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'CPI')

p6 = ggplot(plot_data_6, aes(x = Date, y = GDP_Amount)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'GDP')

p7 = ggplot(plot_data_7, aes(x = Title, y = Houselend_Amount)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'House Lend')

p8 = ggplot(plot_data_8, aes(x = Title, y = Businesslend_Amount)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(x = 'Date', y = 'Business Lend')

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, ncol = 2)
```

Variables' stationarity is crucial for robustness of models and prediction stability, so we need to use Augmented Dickey-Fuller (ADF) test to make sure that the variables are stationary.

Using the testing in levels, we can see except the cash rate target, all other variables are non-stationary because their p-values are lower than 0.05. So we will perform the ADF test on first diiference to confirm whether the variables are stationary.

```{r, warning=FALSE}
#| echo: false
#| label: tbl-adf-level 
#| tbl-cap: ADF test results - Levels 
data_list <- list(
  Cash_Rate_Target = Cash_Rate_Target,
  Unemployment = Unemployment,
  M1 = M1,
  PPI = PPI,
  CPI = CPI,
  GDP = GDP,
  Houselend = Houselend,
  Businesslend = Businesslend
)

adf_results <- lapply(names(data_list), function(name) {
  adf_test_result <- adf.test(data_list[[name]], k = 5)
  data.frame(
    Test = name,
    Test_Statistic = adf_test_result$statistic,
    P_Value = adf_test_result$p.value,
    Lags = 5
  )
})

adf_results <- do.call(rbind, adf_results)
rownames(adf_results) <- NULL
kable(adf_results, "html", align = 'c') %>% 
kable_styling(bootstrap_options = c("striped", "hover"))

```

In the table below. we can see it is clear that in ADF test in first difference, all variables are statistically significant in stationary.

```{r,warning=FALSE}
#| echo: false
#| label: tbl-adf-firstdifference  
#| tbl-cap: ADF test results - First Differences  
adf_diff_results <- lapply(names(data_list), function(name) {
  diff_series <- diff(data_list[[name]])
  adf_test_result <- adf.test(diff_series, k = 5)
  data.frame(
    Test = paste(name, "First Difference", sep = " - "),
    Test_Statistic = adf_test_result$statistic,
    P_Value = adf_test_result$p.value,
    Lags = 5
  )
})

adf_diff_results <- do.call(rbind, adf_diff_results)
rownames(adf_diff_results) <- NULL
kable(adf_diff_results, "html", align = 'c') %>% 
kable_styling(bootstrap_options = c("striped", "hover"))

```

The unit root test's result can also showed from the Autocorrelation Functions (ACF) and Partial Autocorrelation Functions (PACF) plots.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-acf-plot
#| fig-cap: "ACF Plots"
par(mfrow=c(2, 4), mar=c(5, 2, 4, 2) + 0.1, mgp=c(3, 1, 0), cex.main=1, cex.axis=1, cex.lab=1)

for(name in names(data_list)) {
  ts_data <- data_list[[name]]
  Acf(ts_data, main = name)
}
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-pacf-plot
#| fig-cap: "PACF Plots"
par(mfrow=c(2, 4), mar=c(5, 2, 4, 2) + 0.1, mgp=c(3, 1, 0), cex.main=1, cex.axis=1, cex.lab=1)

for(name in names(data_list)) {
  ts_data <- data_list[[name]]
  Pacf(ts_data, main = name)
}

```

## Econometric Model and Hypothesis

To forecast the loan amount in housing and business sector, the Bayesian VAR model will be used in this project. Based on the credit forecast in previous research (Louzis, 2014), we simplify this project's notation of BVAR with $p$ lags below:

```{=tex}
\begin{align}
   y_t &= \mu_0 + A_1y_{t-1}+\dots+A_py_{t-p}+u_t
\end{align}
```
In this model, $y_t=[m1_t$ , $cpi_t$ , $cashrate_t$ , $gdp_t$ , $unemploy_t$ , $ppi_t$ , $houselend_t$ , $businesslend_t]'$ and it includes the eight variables we list above. The variables we used in forecasting is $houselend_t$ and $businesslend_t$. The $u_t$ means the error term, which is assumed to be $u_t|Y_{t-1}\sim\;iidN(\textbf{0}_N,I_N)$, and in this following model $N=8$. $A_l$ with l = 1, 2,...,p is an $N\times N$ coefficient matrix for each lag. We can re-write it into matrix form:

```{=tex}
\begin{align}
  Y &= XA + U \\
  U &\sim MN(0, \Sigma \otimes I_T)
\end{align}
```

where $Y$ is a $T\times N$ matrix with $Y_{T \times N} = \left( y_1', y_2', ..., y_T' \right)'$. $X$ is a $T\times k$ matrix, where $k = 1 + Np$ as $p$ is the lag order. It can be written as $X_{T \times k} = \left( x_1', x_2', ..., x_T' \right)'$ and each $x_t' = (1, y_{t-1}',y_{t-2}',\dots, y_{t-p}')$ which is a $1 \times k$ matrix.$A$ is the $k\times N$ matrix which can be written as $A_{k \times N} = \left( a_0, A_1,A_2 ..., A_p \right)'$. $U_{T\times N} = \left( u_1', u_2', ..., u_T' \right)$ and it is a $T \times N$ matrix.

Through this model, I can make prediction by using information from historical macroeconomic data to estimate the probability distribution of future variables. The outcomes of these estimations will facilitate the interpretation of future loan market trends and the impact of various macroeconomic factors on the loan market.



## Estimation Procedure
```{r}
#Prepare data for BVAR#
start_date <- as.Date("1990-01-01")
end_date <- as.Date("2022-12-31")

date <- seq(from=as.Date("1991-01-01"), to=as.Date("2022-12-31"), by="month")

plot_data = data.frame(date = date, Cash_Rate_Target = plot_data$Cash_Rate_Target)
cash_rate = xts::xts(plot_data$Cash_Rate_Target, plot_data$date)

plot_data_2 = data.frame(date = date, Unemployment = plot_data_2$Unemployment)
unemploy = xts::xts(plot_data_2$Unemployment, plot_data_2$date)

plot_data_3 = data.frame(date = date, M1_Amount = plot_data_3$M1_Amount)
m1 = xts::xts(plot_data_3$M1_Amount, plot_data_3$date)

plot_data_5 = data.frame(date = date, CPI_Amount = plot_data_5$CPI_Amount)
cpi = xts::xts(plot_data_5$CPI_Amount, plot_data_5$date)

plot_data_6 = data.frame(date = date, GDP_Amount = plot_data_6$GDP_Amount)
gdp = xts::xts(plot_data_6$GDP_Amount, plot_data_6$date)

plot_data_7 = data.frame(date = date, Houselend_Amount = plot_data_7$Houselend_Amount)
houselend = xts::xts(plot_data_7$Houselend_Amount, plot_data_7$date)

plot_data_8 = data.frame(date = date, Businesslend_Amount = plot_data_8$Businesslend_Amount)
businesslend = xts::xts(plot_data_8$Businesslend_Amount, plot_data_8$date)

all_data = merge(cash_rate,unemploy,m1,cpi,gdp,houselend,businesslend)


```

```{r static data setup}
#| echo: false
#| message: false
#| warning: false
y             = ts(all_data[,1:ncol(all_data)])
Y             = ts(y[13:nrow(y),], frequency=12)
X             = matrix(1,nrow(Y),1)

for (i in 1:frequency(Y)){
  X           = cbind(X,y[13:nrow(y)-i,])
}
 
## Pre-setup 
N             = ncol(Y)
p             = frequency(Y)
A.hat = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)


# Prior distribution specification - Minnesota prior 
kappa.1       = 10                                    # shrinkage for A1 to Ap
kappa.2       = 100                                   # shrinkage for constant 
A.prior       = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2,1]  = 1
V.prior       = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior       = diag(diag(Sigma.hat))
nu.prior      = N+1
```


```{r}
#| echo: true
#| message: false
#| warning: false
## Posterior sample draw function 
posterior.draws       = function (S, Y, X){
    # normal-inverse Wishard posterior parameters
    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))
    V.bar             = solve(V.bar.inv)
    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
    nu.bar            = nrow(Y) + nu.prior
    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv         = solve(S.bar)
  
    # posterior draws 
    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior   = apply(Sigma.posterior,3,solve)
    Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
    A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
    L                 = t(chol(V.bar))
    for (s in 1:S){
      A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])
    }
 
    output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)
    return(output)
}




## Applying function 
# A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
posterior.sample.draws = posterior.draws(S=120000, Y=Y, X=X)



```

```{r}
    nu.bar            = nrow(Y) + nu.prior
    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))
    V.bar             = solve(V.bar.inv)
    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
    nu.bar            = nrow(Y) + nu.prior
    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv         = solve(S.bar)
    S = 10000
    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)

    
    
    
    
    
```




## Reference

Louzis, Dimitrios P., Macroeconomic and Credit Forecasts in a Small Economy During Crisis: A Large Bayesian VAR Approach (June 1, 2014). Bank of Greece Working Paper No. 184, Available at SSRN: https://ssrn.com/abstract=4184651 or http://dx.doi.org/10.2139/ssrn.4184651

Bańbura, M., Giannone, D., & Lenza, M. (2015). Conditional forecasts and scenario analysis with vector autoregressions for large cross-sections. International Journal of Forecasting, 31(3), 739-756. https://doi.org/10.1016/j.ijforecast.2014.08.013.
